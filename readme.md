# Radiomics-based Multiclass Classification of Organs

This repository contains the code for a machine-learning-based multiclass classification challenge using radiomics features extracted from medical images. The objective of this project is to classify medical images into multiple categories based on the radiomic features extracted by machine learning method.

# Introduction

This project is designed to tackle a significant challenge in medical imaging: classifying medical images from multiple categories using machine learning techniques. The challenge aims to: 1. leverage radiomic features to build a multiclass classification model and 2. generate predictions using trained machine learning models. Radiomic features, which are quantitative measures extracted from medical images, provide a rich source of data that can enhance diagnostic accuracy. By developing and validating robust machine learning models, this project seeks to improve clinical diagnosis and decision-making.

# Dataset

The dataset used in this challenge is shared with GitHub, which consists of images and corresponding masks from 66 cases. There are totally 5 different categories: 'bone', 'kidney', 'liver', 'muscle', and 'spleen'.

Data Structure

- data
  - images
    - 1_liver7.nrrd
    - ...
  - Masks
    - 1_liver7.nrrd
    - ...

# Preprocessing

if both images and masks are present, we considered the case to be valid. Based on this logic, A list of all eligible cases was generated.

# Feature extraction

The extractor from Pyradiomic was initialized with all features (like first order statistics, shape-based statistics and so on) and all image types (like LoG, square and so on) enabled.

To avoid possible crashes during extraction, radiomic features from each case were extracted separately and stored in the corresponding Excel files. And all these Excel files were concatenated afterwards.

# Data preparation

Based on the names of nrrd files, the Y label (which organ the image comes from, like the kidney) was generated (column name: Origin) using regular expression. The distribution of Y label was visualized by a bar plot. 

![Y_distribution](/Users/u0126415/Documents/Code_challenge_Essen/coding_challenge_mml_postdoc-main/data/Train_Validate/computation/Y_distribution.jpg)

Since the scikit-learn models assume the Y label expressed as integers, a new numeric column named "Origin_num" was generated by mapping with the column named "Origin". A stratified random split was performed to generate training data and test data which were subjected to z-scored normalization.

# Feature selection

Radiomics features were selected in an unsupervised way by removing one of the highly correlated feature pairs by a predefined threshold for the correlation coefficient. After this, supervised feature selection by LASSO regression was performed, which was repeated 100 times based on batches sampled differently from training data. Following concatenation of results of 100 cycles of LASSO regression, features were selected if it appeared in more than 20% of 100 cycles.

![relative_importance](/Users/u0126415/Documents/Code_challenge_Essen/coding_challenge_mml_postdoc-main/Train_Validate/computation/relative_importance.jpg)



# Model Training and Evaluation

Here, we adopted different algorithms available in sci-kit learn library, including Random Forests, XGBoost and so on. To yield optimal performance of these algorithms, hyperparameter tuning by grid search was adopted, with "roc_auc_ovr" as the metric for tuning. For the evaluation of the model performance, metrics like Matthew correlation coefficient, Cohen kappa, log loss, auc-ovr-weighted, weighted f1 value, precision and recall, were used, given the multiclass classification nature. Additionally, the bootstrapping method to calculate the 95% confidence interval was adopted.

![LDA](/Users/u0126415/Documents/Code_challenge_Essen/coding_challenge_mml_postdoc-main/data/Train_Validate/computation/LDA.jpg)



# Prediction

After the models have been trained and validated, we may also apply these models to generate predictions. This pipeline includes radiomic feature extraction, data normalization, load model and make prediction.

# Usage

To use the current pipeline, you can do as follows.

- Copy the folder containing all Python script files and requirements.txt to the project folder containing folder structure like this
  - Project folder
    - data
      - images
        - 1_liver7.nrrd
        - ...
      - masks
        - 1_liver7.nrrd
        - ...
    - python_script
      - initialization.py
      - ...
    - output folder named train_validate or predict
      - ...
- In the terminal, change the directory to the python_script folder
- Install python libraries by
  - $ pip install requirements.txt
- Run the following codes depending on your purpose
  - If you would like to train and validate models, which you normally do first, you can run "train_validate" mode as follows.
    - $ python task_execution.py --setting train_validate
  - After training the model based on the codes above, if you would like to apply the trained models to new data, you can run "predict" mode as follows.
    - $ python task_execution.py --setting predict

# Result Structure

- In "train_validate" mode, all output is stored in a folder named "train_validate" within the parent folder. You can find the following subfolders.
  - code: the folder to store all the Python scripts based on which the results were calculated. This is for tracing and debugging purposes.
  - computation: the folder to store Excel files and plots
    - Excel files:
      - Summarized_CI.xlsx: The file summarizes different models' performance by different evaluation metrics with 95% confidence interval.
      - Recall.xlsx, Precision.xlsx, f1.xlsx, auc.xlsx, log_loss.xlsx, Cohen.xlsx, MCC.xlsx: The files store the value for each evaluation metric by algorithms in each bootstrapping cycle.
      - output.xlsx: The file stores the point estimate of different models' performance.
      - output_prob.xlsx: The file stores the probability to be classed as each category for all algorithms.
    - Plots:
      - Y_distribution.jpg: The plot shows the distribution of the Y label (origin organ) of all 66 cases.
      - relative_importance.jpg: The plot shows the relative importance of selected features in descending order.
      - Neural network.jpg, AdaBoost.jpg, Extra trees.jpg, SVM.jpg, LDA.jpg, KNN.jpg, CART.jpg, XGBoost.jpg, Naive Bayes.jpg, Random forests.jpg, Logistic.jpg: The files show the confusion matrix for the respective algorithm.
  - LASSO: the folder storing files generated during LASSO regression.
    - Lasso_seed_x.xlsx: This series of files contained name for features with non-zero coefficient and corresponding coefficient.
    - Complie_100.xlsx: The file stores concatenated and processed results from previous LASSO regressions.
  - log: The folder contains files generated during model training and validation.
    - df_normalized.xlsx, df_train_normalized.xlsx, df_test_normalized.xlsx: dataframes stored normalized data, normalized training data and normalized test data.
    - selected_features.xlsx: the file stores the names of selected features.
    - tuned_para.xlsx: the file stores the tuned parameters for each algorithm.
    - y_rename_dict.xlsx: the file stores the mapping dictionary between Y label in string and Y label in number.
  - models: the folder storing trained model and scaler for normalization.
    - x.sav: trained model files for each algorithm
    - scaler.bin: scaler for normalization.
  - radiomics_features: the folder storing radiomics features from each case
- In "predict" mode, all output is stored in a folder named "predict" within the parent folder. You can find the following subfolders.
  - code: the folder to store all the Python scripts based on which the results were calculated. This is for tracing and debugging purposes.
  - computation: the folder to store Excel files and plots
    - Excel files:
      - Summarized_CI.xlsx: The file summarizes different models' predictions for each case.
      - Prediction_Neural network.xlsx, Prediction_AdaBoost.xlsx, Prediction_Extra trees.xlsx, Prediction_SVM.xlsx, Prediction_LDA.xlsx, Prediction_KNN.xlsx, Prediction_CART.xlsx, Prediction_XGBoost.xlsx, Prediction_Naive Bayes.xlsx, Prediction_Random forests.xlsx, Prediction_Logistic.xlsx: The files store predicted class and probabilities for each category.
  - log: The folder contains files generated during model prediction.
    - df_normalized.xlsx: dataframe stored normalized data.
  - radiomics_features: the folder storing radiomics features from each case

# Requirements

numpy==1.26.4
pandas==1.5.3
pyradiomics==v3.0.1
scipy==1.10.0
trimesh==3.22.3
matplotlib==3.7.0
scikit-learn==1.2.1
xgboost==1.7.5
joblib==1.1.1

# License

This project is licensed under the MIT License. 

You are free to use, modify, and distribute this software under the conditions stated in the MIT License. See the [LICENSE](LICENSE) file for more details.